Calculate Big O
Once you have completed your solution for each problem,
perform a run time analysis (Worst Case Big-O Notation) of your solution.
Document this for each problem and include this in your submission.

Task0: O(1)
Let us assume that time taken to read CSV file will take constant time.
So, we can directly fetch the first and last record from the dataset using
index 0 for the first record of text and -1 for the last record of call respectively.
It will take constant time i.e O(1).


Task1: O(n+m)
We are traversing the calls and text data sets and storing the values into a set.
Traversing both the data set will take linear time.
So we can say that time taken is O(n+m) where n and m are the lengths of dataset calls and texts respectively.


Task2: O(n) or O(n * m)
We are traversing the calls dataset and storing key pair value into a dictionary.
Traversing the calls dataset will take linear time.
We are also searching through the dictionary with in the for loop and in amortized worst case for it will take linear time.
So we can say that time taken is O(n * m) where n is the length of calls data and m is the length of telephone call time dictionary in amortized worst case.
We can also say that time taken is O(n) where the telephone call time dictionary doesnt affect the time complexity as much (which will be O(1))


Task3: O(n)
Part A
In part A, we are traversing the calls data set and storing the values into a set.
Then we sort the set and loop through set to display each element.
Traversing the data set will take linear time.
It is safe to assume .find() method will take constant time because we check for ( prior to the method call.
The sorted method will take quasilinear time.
Traversing the set will take linear time.
So we can say that time take is O(n) + O(m) + O(m log m) where n is the length of call data set and m is the length of set respectively.
Since O(m) is less than O(m log m) we can rewrite the complexity as O(n) + O(m log m).
Additionally, we know that m is a subset of n which means m will never be greater than m.
Thus, we can further condense the complexity to O(n).

Part B
In part B, we are traversing the calls data set and counting each element that starts with "(080)".
Traversing the data set will take linear time.
So we can say that time taken is O(n) where n is the length of data set calls and respectively.

Conclusion:
The time complexity of the whole file will be O(n) + O(n) which is equivalent to O(2n).
Because we are looking for the worst time complexity we can drop the constant,
leaving us with O(n).


Task4: O(q * r)
We are traversing the calls data set and storing the values into a set only for outcalls.
Traversing the data set will take linear time.
So we can say that time taken is O(n) where n is the length of data set calls respectively.

Then, we are traversing the calls and text data sets and storing the incoming calls, sent text numbers, and receiving text numbers.
Traversing both the data set will take linear time.
So we can say that time taken is O(m + p) where m is the lengths of datasets calls and texts respectively.

Then, we traverse the outcall set check if it contains in the except_call set and if it is not in that set then we store that value into a list.
Traversing outcall set and inside the loop we are again iterating through the other set will take quadratic time.
So we can that time taken is O(q * r) where q and r are the lengths of datasets outcall numbers and every other phone numbers respectively.

Finally, we traverse through the possible telemarketer number to print and before that we will sort that dataset.
So we can say that time taken is O(s) + O(s log s) where s is the length of dataset.

Conclusion:
The time complexity of the whole file will be O(n) + O(m + p) + O(q * r) + O(s) + O(s log s)
Because we are looking for the worst time complexity we can just take the quadratic time and drop the other values.
Thus, the we are left with O(q * r).



